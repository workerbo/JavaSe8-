[Kafak基本概念](https://zhuanlan.zhihu.com/p/114624982)



###### HA

它是由多个Broker组成的，每个Broker都是一个节点，小伙伴们是不是想到了RocketMQ的Broker呢。当我们创建Topic的时候，这个Topic是会划分成多个partition的，每个partition又可以存在不同的Broker上，这里的每个partition都会放一部分数据，可以把它理解成一个分片。

由此可见，**Kafka是一个天然的分布式消息队列，它的Topic是分成多个partition分布到多个Broker上存储的。**多分区多副本。

提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，要是你可以随意读写每个 follower，那么就要 考虑数据一致性的问题，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。

写数据的时候，生产者就向 leader写数据，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）

消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。



生产者端：

默认的分区策略是：

- 如果在发消息的时候指定了分区，则消息投递到指定的分区
- 如果没有指定分区，但是消息的key不为空，则基于key的哈希值来选择一个分区
- 如果既没有指定分区，且消息的key也是空，则用轮询的方式选择一个分区



消费者端：

消费者以组的名义订阅主题，主题有多个分区，消费者组中有多个消费者实例

同一时刻，一条消息只能被组中的一个消费者实例消费

消费者组订阅这个主题，意味着主题下的所有分区都会被组中的消费者消费到，如果按照从属关系来说的话就是，主题下的每个分区只从属于组中的一个消费者，不可能出现组中的两个消费者负责同一个分区。

在消费者加入到消费组后，消费者Leader会根据当前在线消费者个数与分区的数量进行队列负载，每一个消费者获得一部分分区

如果消费者实例的数量大于分区数，那么按照默认的策略（PS：之所以强调默认策略是因为你也可以自定义策略），有一些消费者是多余的，一直接不到消息而处于空闲状态。

Kafka它在设计的时候就是要保证分区下消息的顺序，也就是说消息在一个分区中的顺序是怎样的，那么消费者在消费的时候看到的就是什么样的顺序，那么要做到这一点就首先要保证消息是由消费者主动拉取的（pull），其次还要保证一个分区只能由一个消费者负责。



位移：

对于Kafka中的分区而言，它的每条消息都有唯一的offset，用来表示消息在分区中的位置。当我们调用poll()时，该方法会返回我们没有消费的消息。当消息从broker返回消费者时，broker并不跟踪这些消息是否被消费者接收到；Kafka让消费者自身来管理消费的位移，并向消费者提供更新位移的接口，这种更新位移方式称为提交（commit）
      **位移提交是在消费完所有拉取到的消息之后才执行的**，如果不能正确提交偏移量，就可能发生数据丢失或重复消费。

在 Kafka 中默认的消费位移的提交方式是 **自动提交**。会出现消息重复或者消息丢失，【间隔一定时间提交了位移】

手动提交offset的方法有两种：分别是commitSync（同步提交）和commitAsync（异步提交）。两者的相同点是，都会将**本次poll的一批数据最高的偏移量提交**；不同点是，commitSync阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而commitAsync则没有失败重试机制，故有可能提交失败。



参考：

https://www.cnblogs.com/lm970585581/p/13652841.html