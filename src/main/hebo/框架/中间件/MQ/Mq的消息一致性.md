 mysql的binlog同步。你再mysql里增删改3条binlog。接着这三条binlog发送到MQ里面。到消费出来依次执行。起码要保证人家是按照顺序来的吧。不然本来是增加、修改、删除。你愣是给更改了顺序，换成了删除、修改、增加。这就乱了。

 1个生产者，多个消费者。生成的顺序是数据1、数据2、数据3.消费的数据是数据2、数据1、数据3。没有按之前的顺序。

搞3个Queue，每个消费者就消费其中的一个Queue。**把需要保证顺序的数据发到1个Queue**里去。

##### RabbitMQ保证消息顺序性

RabbitMQ：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦，或者就是一个queue，但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理。【需要的有序的就分发到一个worker里】


##### Kafka保证消息消息顺序性

一个topic，一个partition，一个consumer，内部单线程消费，写N个内存，然后N个线程分别消费一个内存queu即可。注意，kafka中，写入一个partition中的数据，一定是有顺序的。

但是在一个消费者的内部，假设有多个线程并发的进行数据的消费，那么这个消息又会乱掉。

这样时候，我们需要引入内存队列，然后我们通过消息的key，然后我们通过hash算法，进行hash分发，将相同订单key的散列到我们的同一个内存队列中，然后每一个线程从这个Queue中拉数据，同一个内存Queue也是有顺序的。