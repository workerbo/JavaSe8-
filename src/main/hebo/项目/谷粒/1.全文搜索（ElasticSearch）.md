---
typora-copy-images-to: assert
typora-root-url: assert
---

# 描述

![1597501750467](/1597501750467.png)

```properties
1.简介：存储 + 检索 + 分析

2.作用：
	1）快速存储、搜索和分析海量数据（比mysql快）
	2）es的数据来自mysql，需要从mysql提取数据到es中
	3）Elastic是Lucene的封装，提供了REST AP|的操作接口
	4）日志处理和分析
    5）基础设施指标和容器监测
    6）应用程序性能监测
    7）地理空间数据分析和可视化
    8）安全分析
    9）业务分析
    
3.端口
	9200：HTTP
	9300：TCP
	5601：kibana
```

# 概念

```properties
1.lndex（索引）：相当于mysql中的database
2.Type（类型）：相当于mysql中的table
3.Document（文档）：相当于mysql中的一条记录（es以json格式存储）
4.倒排索引
	1）es存储数据至索引时，还会同时维护一张倒排索引表
	当插入记录时，会将当前记录拆为单词存入，并保存记录与单词的对应关系
	2）此时检索一条记录"红海特工行动"，首先会将记录分词为 "红海"、"特工"、"行动"，然后在倒排索引表中匹配单词（不用直接检索文档，比mysql快【mysql需要使用like匹配每一条记录】），并根据相关性得分排序
	3）相关性得分简要说明：例如记录3：3个词命中2个
	  					  记录5：4个词命中2个，记录3得分 > 记录5得分

```

![1634132956478](/1634132956478.png)

![1634133237935](/1634133237935.png)

# 初步检索

## 1._cat查询

```
GET 192.168.56.10:9200/_cat/nodes：查看所有节点
GET 192.168.56.10:9200/_cat/health：查看es健康状况
GET 192.168.56.10:9200/_cat/master：查看主节点信息
GET 192.168.56.10:9200/_cat/indices：查看所有索引show databases;
```

## 2.新增/修改文档（方法1）

```json
1.使用POST请求
192.168.56.10:9200/customer/external/1
{
    "name": "John Doe"
}
	1）不指定ID，新增一条记录并自动生成ID返回
	2）指定ID，数据不存在则新增，数据存在则修改并新增版本号
解析：
	customer：索引
	external：类型
	1：唯一ID标示


2.使用PUT请求
	1）不指定ID，报错
	2）指定ID，数据不存在则新增，数据存在则修改并新增版本号（一般用于修改）
192.168.56.10:9200/customer/external/1
{
    "name": "John Doe"
}

3.更新操作时，可以新增属性，新增age属性
192.168.56.10:9200/customer/external/1
{
    "name": "John Doe",
    "age": 13
}
```

```json
新增成功返回参数：【不会返回保存的数据，需要调用GET查询文档数据】
{
    "_index": "customer",// 索引
    "_type": "external",// 类型
    "_id": "1",// 唯一标示
    "_version": 1,// 版本号
    "result": "created",// 操作类型
    "_shards": {// 
        "total": 2,
        "successful": 1,
        "failed": 0
    },
    "_seq_no": 0,
    "_primary_term": 1
}
```

## 3.查询文档（无参查询）

```json
无相关性得分

1.GET请求：索引/类型/唯一标示ID
192.168.56.10:9200/customer/external/1
返回数据组成：索引、类型、id、版本、结果、分片
```

```json
返回结果：
{
    "_index": "customer",
    "_type": "external",
    "_id": "1",
    "_version": 3,
    "_seq_no": 2,// 并发控制字段，每次更新就会+1，用来作乐观锁
    "_primary_term": 1,// 同上，主分片重新分配，如重启，就会变化
    "found": true,// 查询成功
    "_source": {// 文档数据
        "name": "John Doe"
    }
}

192.168.56.10:9200/customer/external/2
{
    "_index": "customer",
    "_type": "external",
    "_id": "2",
    "found": false// 查询失败
}
```

## 4.乐观锁

```json
1.解释CAS（compare and swap）：
	比较交换是一个原子操作，获取seq_no值与预期seq_no值比较是否相等，
	1）相等则更新数据
	2）不相等则更新失败，需要重新获取seq_no作为预期值然后做CAS操作
	
2.实现，以下demo使用PUT操作
	1）先查询seq_no作为预期值：192.168.56.10:9200/customer/external/1
	返回值：
{
    "_index": "customer",
    "_type": "external",
    "_id": "1",
    "_version": 3,
    "_seq_no": 2,
    "_primary_term": 1,
    "found": true,
    "_source": {
        "name": "John Doe"
    }
}

	2）带上预期值执行两次CAS操作，只有一个会成功
	当执行第一次时seq_no值被改变，第二次进来预期值与真实seq_no不相等，更新失败
------------------------------------------------------------------
执行第一次
192.168.56.10:9200/customer/external/1?if_seq_no=2&if_primary_term=1
{
    "name": "John Doe2"
}

修改成功，返回：
{
    "_index": "customer",
    "_type": "external",
    "_id": "1",
    "_version": 4,
    "result": "updated",
    "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
    },
    "_seq_no": 3,// 值已更新
    "_primary_term": 1
}
------------------------------------------------------------------
执行第二次，seq_no预期值仍然是2，与实际值seq_no=3不相等，CAS失败
192.168.56.10:9200/customer/external/1?if_seq_no=2&if_primary_term=1
{
    "name": "John Doe3"
}
修改失败返回409
{
    "error": {
        "root_cause": [
            {
                "type": "version_conflict_engine_exception",
                "reason": "[1]: version conflict, required seqNo [2], primary term [1]. current document has seqNo [3] and primary term [1]",
                "index_uuid": "X0p28Y5FQvy344rl9EXhrg",
                "shard": "0",
                "index": "customer"
            }
        ],
        "type": "version_conflict_engine_exception",
        "reason": "[1]: version conflict, required seqNo [2], primary term [1]. current document has seqNo [3] and primary term [1]",
        "index_uuid": "X0p28Y5FQvy344rl9EXhrg",
        "shard": "0",
        "index": "customer"
    },
    "status": 409
}
```

```properties
注：
	老版本用version
	新版本用seq_no
```

## 5.修改文档（方法2）

```json
1._update，可以增加字段：
POST	192.168.56.10:9200/customer/external/3/_update
{
    “doc”:{
        "name":"test",
        "age":"13"	// 还可以增加字段
    }
}
与方法1修改文档的区别：
	_update方式修改会对比源数据，如果数据一致没有更改，则result属性值是noop（no operation），且版本号不变，序列号不变
路径带_update ，要在参数外套一层doc
```



## 6.删除数据（索引/类型）

```json
1.删除文档
发送delete请求，指定索引/类型/ID
DELETE 192.168.56.10:9200/customer/external/3

2.删除索引
发送delete请求，指定索引
DELETE 192.168.56.10:9200/customer/external/3

注：没有删除类型操作
```

```
返回参数：
{
    "_index": "customer",
    "_type": "external",
    "_id": "3",
    "_version": 2,
    "result": "deleted",
    "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
    },
    "_seq_no": 6,
    "_primary_term": 6
}
```

## 7.批量操作

```json
使用kibana测试：
访问：192.168.56.10:5601=>点击Dev Tools

1.语法格式，两个json体为一个操作（不是事务操作，没有回滚）
例1：指定索引/类型的批量操作，并创建/修改两条文档：【index表示创建或修改操作】
POST customer/external/_bulk
{"index":{"_id":"1"}} 
{"name": "John Doe"}
{"index":{"_id":"2"}}
{"name": "Paul Doe"}
解析：
	1）index：索引一条文档（保存），并指定ID
	2）第二个json体是文档数据

action 必须是以下选项之一：

create：如果文档不存在，那么就创建它，存在的话，就会报错，发生异常报错不会影响其他操作
index：创建一个新文档或者替换一个现有的文档
update：部分更新一个文档
delete：删除一个文档
metadata 中需要指定要操作的文档的 _index、_type 和 _id，同时_index、_type也可在url中指定

回参：
{
  "took" : 13,// 毫秒数
  "errors" : false,
  "items" : [
    {
      "index" : {
        "_index" : "customer",
        "_type" : "external",
        "_id" : "1",
        "_version" : 6,
        "result" : "updated",
        "_shards" : {
          "total" : 2,
          "successful" : 1,
          "failed" : 0
        },
        "_seq_no" : 8,
        "_primary_term" : 6,
        "status" : 200
      }
    },
    {
      "index" : {
        "_index" : "customer",
        "_type" : "external",
        "_id" : "2",
        "_version" : 1,
        "result" : "created",
        "_shards" : {
          "total" : 2,
          "successful" : 1,
          "failed" : 0
        },
        "_seq_no" : 9,
        "_primary_term" : 6,
        "status" : 201
      }
    }
  ]
}

```

```json
例2：在请求url上不指定索引、类型
POST _bulk
{"delete":{"_index":"website","_type":"blog","_id":"123"}}//删除文档
{"create":{"_index":"website","_type":"blog","_id":"123"}}//新建文档
{"title":"My first blog post"}
{"index":{"_index":"website","_type":"blog"}}//创建/更新文档
{"title":"My second blog post"}
{"update":{"_index":"website","_type":"blog","_id":"123","_retry_on_conflict":3}}//更新文档
{"doc":{"title":"My updated blog post"}}
```

## 8.导入批量测试数据

```
POST /bank/account/_bulk
```



# 官方文档

```
https://www.elastic.co/cn/
1.版本：7.5
学习-》文档-》Elasticsearch: Store, Search, and Analyze
-》Elasticsearch Guide [7.15] — other versions -》选择7.5版本
-》Getting started with Elasticsearch-》Start searching

2.版本：7.15
学习-》文档-》Elasticsearch: Store, Search, and Analyze
-》Elasticsearch Guide [7.15] — other versions -》Quick start

```

![1634465390843](/1634465390843.png)



# 进阶检索

## 1.SearchAPI（带参查询）

```json
1.三种查询方式，SearchAPI是方式2
2.方法2和方法3查询结果封装在"hits":{}中，表示命中的文档
```



```json
1.根据ID查询：
GET customer/external/1【GET 192.168.56.10:9200/customer/external/1】
查询结果封装在"_source":{}中

2.在URL直接拼接参数查询【结果默认分页，有相关性得分】：
GET bank/_search?q=*&sort=account_number:asc
GET /index/type/_search?q=属性名:属性值
GET /index/type/_search?q=+属性名:属性值
GET /index/type/_search?q=-属性名:属性值
也可以省略属性名, 直接q=属性值
GET /index/type/_search?q=属性值
在插入一条document时, ES会自动将多个field的值, 全部用字符串的方式串联起来, 变成一个长的字符串(以空格作为分隔符)，作为_all field的值

3.使用请求体查询：【返回结果中_source只返回指定属性，有相关性得分】
注意：该请求实际是POST请求，在Postman中需使用POST请求+请求体传参的方式调用该查询




基本语法格式
一个查询语句的典型结构:
﻿
QUERY_NAME:{
﻿
   ARGUMENT:VALUE,
﻿
   ARGUMENT:VALUE,...
﻿
}  或者
    {
  QUERY_NAME:{
     FIELD_NAME:{
       ARGUMENT:VALUE,
       ARGUMENT:VALUE,...
      }   
   }
}



GET bank/_search
{
	"query": {
		"match_all": {}
	},
	"sort": [{
			"account_number": "asc"// 按照账号升序排列
		},
		{
			"balance": "desc"// 按照余额降序排列
		}
	],
	"from": 10,// 第10条数据开始
	"size": 10,// 共取10条数据
	"_source": ["account_name", "balance"]
}
```

```json


查询结果：
{
	"took": 18,// 查询时间
	"timed_out": false,
	"_shards": {
		"total": 1,
		"successful": 1,
		"skipped": 0,
		"failed": 0
	},
	"hits": {// 命中结果
		"total": {
			"value": 1000,// 命中数据条数
			"relation": "eq"
		},
		"max_score": null,// 最大相关性得分（不是模糊匹配所以是null）
		"hits": [{// 命中数据详情集合
			"_index": "bank",// 索引
			"_type": "account",// 类型
			"_id": "0",// 唯一标示
			"_score": null,// 得分
			"_source": {// json文档
				"account_number": 0,
				"balance": 16623,
				"firstname": "Bradshaw",
				"lastname": "Mckenzie",
				"age": 29,
				"gender": "F",
				"address": "244 Columbus Place",
				"employer": "Euron",
				"email": "bradshawmckenzie@euron.com",
				"city": "Hobucken",
				"state": "CO"
			},
			"sort": [// 排序
				0
			]
		}]
	}
}    
```

## 2.Quyry DSL 语法

```properties
1.在官网查看语法
2.Quyry DSL是针对POST请求+参数体方式查询文档的语法
3.以下查询demo中的GET表示在Kibana中可以写成GET请求，实际会被Kibana代理为POST请求（postman中需要使用post请求方式+请求体的格式调用）
4.有相关性得分
```

### 2.1.match_all

```json
查询参数统一放进query中
相当于没有where条件

GET bank/_search
{
	"query": {
		"match_all": {}// 匹配所有，但结果会默认分页
	}
}
```

### 2.2.排序

```json
1.方式1：
GET bank/_search
{
	"query": {
		"match_all": {}
	},
	"sort": [{
		"account_number": {
			"order": "desc"
		}
	}]
}

2.方式2：简介写法
GET bank/_search
{
	"query": {
		"match_all": {}
	},
	"sort": [{
			"account_number": "asc"// 按照账号升序排列
		},
		{
			"balance": "desc"// 按照余额降序排列
		}
	]
}
```

### 2.3.分页

```json
GET bank/_search
{
	"query": {
		"match_all": {}
	},
	"sort": [{
			"account_number": "asc"// 按照账号升序排列
		},
		{
			"balance": "desc"// 按照余额降序排列
		}
	],
	"from": 10,// 第10条数据开始
	"size": 10,// 共取10条数据
}
```

### 2.4.返回指定字段

```json
GET bank/_search
{
	"query": {
		"match_all": {}
	},
	"_source": ["account_name", "balance"]
}
```

### 2.5.match（精确/模糊查询）

```json
查询参数统一放进query中

返回参数包含匹配值

1.精确匹配-查询数值类型字段：非文本推荐使用 term
词条查询
 term query会去倒排索弓|中寻找确切的term,它并不知道分词器的存在。这种查询适合keyword、numeric. date.
term表示查询某个字段里含有某个关键词的文档，terms表示查询某个字段里合有多个关键词的文档
match ：全文（Fulltext）查询
operator：用来控制match查询匹配词条的逻辑条件，默认值是or，如果设置为and，表示查询满足所有条件；
minimum_should_match：当operator参数设置为or时，该参数用来控制应该匹配的分词的最少数量；
match和term会根据检索字段类型区分不同的行为？
GET bank/_search
{
  "query": {
    "match": {
    	"account_number": 20
    }
  }
}
 "operator": "and"  

2.模糊匹配-分词查询字符串类型字段：
会将address拆分成mill + lane分别模糊匹配，例如会查出288 Mill Street/685 School Lane
GET bank/_search
{
  "query": {
    "match": {
    	"address": "mill lane"
    }
  }
}

3.精确匹配-查询字符类型字段：【只有text文本字段可以调用 .keyword】
GET bank/_search
{
  "query": {
    "match": {
    	"address.keyword": "198 Mill Lane"
    }
  }
}
match即全文检索，对检索字段进行分词匹配，会按照响应的评分 _score 排序，原理是倒排索引。
text: 在写入时，对写入的值进行分词，然后一一插入到倒排索引。
keyword: 在写入时，将整个值插入到倒排索引中，不进行分词。
keyword属性的设置是添加了一个额外字段，这个字段就是source.keyword，也就是es在source字段之下额外生成添加了一个属性字段是keyword，这个keyword才是真正的不分词的索引字段，source.keyword字段才是真正意义上的不分词处理字段。而索引也是索引该字段才是真正的精确匹配

# 这里的查找是精确查找，只有完全匹配时才会查找出存在的记录，
# 如果想模糊查询应该使用match_phrase 短语匹配
```

### 2.6.match_phrase（短语匹配）

```json
称为短语搜索，要求所有的分词必须同时出现在文档中，同时位置必须紧邻一致。【会分词】
slop 参数-Token之间的位置距离容差值

GET bank/_search
{
  "query": {
    "match_phrase": {
    	"address": "mill lane"
    }
  }
}
```

### 2.7.multi_match（多字段分词匹配同一条件）

```json
multi_match：多个字段分词模糊匹配，state和address都对Mill Road作分词匹配
GET bank/_search
{
  "query": {
    "multi_match": {
    	"query": "Mill Road",
    	"fields":["state", "address"]
    }
  }
}
```

### 2.8.bool（复合查询must）

```json
bool：多条件and + or
	must：必须满足，影响相关性得分【也可以不写must直接match】
	must_not：必须不满足，不影响相关性得分，被看做filter
	should：可以满足，只对must和must_not匹配结果的影响相关性得分有影响【不满足的不会被过滤】

GET bank/_search
{
	"query": {
		"bool": {
			"must": [{
					"match": {
						"gender": "M"
					}
				},
				{
					"match": {
						"address": "mill"
					}
				}
			],
			"must_not": [{
				"match": {
					"age": "28"
				}
			}],
			"should": [{
				"match": {
					"lastname": "Hines"
				}
			}]
		}
	}
}
```

### 2.9.filter（结果过滤）

```json
1.过滤不影响相关性得分
2.must_not是过滤器的一种

案例1：查询年龄 10 <= age <= 30的记录，返回结果相关性得分全是0.0
GET bank/_search
{
  "query": {
    "bool": {
      "filter": [
        {
          "range": {
            "age": {
              "gte": 10,
              "lte": 30
            }
          }
        }
      ]
    }
  }
}

案例2：查询gender=M，address like "mill"，match != 28，10 <= age <= 30的记录
GET bank/_search
{
	"query": {
		"bool": {
			"must": [{
					"match": {
						"gender": "M"
					}
				},
				{
					"match": {
						"address": "mill"
					}
				}
			],
			"must_not": [{
				"match": {
					"age": 28
				}
			}],
			"should": [{
				"match": {
					"lastname": "Hines"
				}
			}],
			"filter": [{
				"range": {
					"age": {
						"gte": 10,
						"lte": 30
					}
				}
			}]
		}
	}
}
```

### 2.10.term

```json
1.全文检索（分词）的字段不建议使用term，精确查询的字段使用
  text类型的字段如果使用term查询可能会查询不到，因为保存text字段的时候存在分词的问题，要查出来是很困难的
  解决方案：
	1）使用match + field.keyword的方式精确查询
	2）使用match_phrase进行短语匹配（不分词）【仍然是模糊匹配】

2.会贡献相关性得分，精确匹配

3.案例：
GET bank/_search
{
  "query": {
    "term": {
    	"age": 28
    }
  }
}
```

## 3.分析aggregations（聚合函数）

```json
1.分组 和 聚合函数等功能
2.聚合结果包装在 "aggregations":{"buckets"}中
3.更多的聚合查看官方文档
```

### 3.1.terms

```json
1.搜索address包含mill的所有人的年龄分布【类似于分组求和】
注意：对于text字段使用terms聚合时，需要使用field.keyword，详见3.5根据性别聚合

GET bank/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "address": "mill"
          }
        }
      ]
    }
  },
  "aggs": {// 使用聚合
    "ageAgg": {// 取一个聚合名称
      "terms": {
        "field": "age",// 根据age字段统计
        "size": 10// 返回前10条统计结果
      }
    }
  }
}
```

```json
返回结果：
{
  "took" : 26,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 4,
      "relation" : "eq"
    },
    "max_score" : 5.4032025,
    "hits" : [
      {
        "_index" : "bank",
        "_type" : "account",
        "_id" : "970",
        "_score" : 5.4032025,
        "_source" : {
          "account_number" : 970,
          "balance" : 19648,
          "firstname" : "Forbes",
          "lastname" : "Wallace",
          "age" : 28,
          "gender" : "M",
          "address" : "990 Mill Road",
          "employer" : "Pheast",
          "email" : "forbeswallace@pheast.com",
          "city" : "Lopezo",
          "state" : "AK"
        }
      },
      {
        "_index" : "bank",
        "_type" : "account",
        "_id" : "136",
        "_score" : 5.4032025,
        "_source" : {
          "account_number" : 136,
          "balance" : 45801,
          "firstname" : "Winnie",
          "lastname" : "Holland",
          "age" : 38,
          "gender" : "M",
          "address" : "198 Mill Lane",
          "employer" : "Neteria",
          "email" : "winnieholland@neteria.com",
          "city" : "Urie",
          "state" : "IL"
        }
      },
      {
        "_index" : "bank",
        "_type" : "account",
        "_id" : "345",
        "_score" : 5.4032025,
        "_source" : {
          "account_number" : 345,
          "balance" : 9812,
          "firstname" : "Parker",
          "lastname" : "Hines",
          "age" : 38,
          "gender" : "M",
          "address" : "715 Mill Avenue",
          "employer" : "Baluba",
          "email" : "parkerhines@baluba.com",
          "city" : "Blackgum",
          "state" : "KY"
        }
      },
      {
        "_index" : "bank",
        "_type" : "account",
        "_id" : "472",
        "_score" : 5.4032025,
        "_source" : {
          "account_number" : 472,
          "balance" : 25571,
          "firstname" : "Lee",
          "lastname" : "Long",
          "age" : 32,
          "gender" : "F",
          "address" : "288 Mill Street",
          "employer" : "Comverges",
          "email" : "leelong@comverges.com",
          "city" : "Movico",
          "state" : "MT"
        }
      }
    ]
  },
  "aggregations" : {
    "ageAgg" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 0,
      "buckets" : [
        {
          "key" : 38,
          "doc_count" : 2
        },
        {
          "key" : 28,
          "doc_count" : 1
        },
        {
          "key" : 32,
          "doc_count" : 1
        }
      ]
    }
  }
}

```

### 3.2.avg

```json
1.搜索address包含mill的所有人的年龄分布【类似于分组求和】
  和平均年龄 + 平均薪资
GET bank/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "address": "mill"
          }
        }
      ]
    }
  },
  "aggs": {
    "ageAgg": {
      "terms": {
        "field": "age",
        "size": 10
      }
    },
    "ageAvg":{
      "avg": {
        "field": "age"
      }
    },
    "blanceAvg":{
      "avg": {
        "field": "balance"
      }
    }
  }
}
```

```json
{
  "took" : 3,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 4,
      "relation" : "eq"
    },
    "max_score" : 5.4032025,
    "hits" : [
      {
        "_index" : "bank",
        "_type" : "account",
        "_id" : "970",
        "_score" : 5.4032025,
        "_source" : {
          "account_number" : 970,
          "balance" : 19648,
          "firstname" : "Forbes",
          "lastname" : "Wallace",
          "age" : 28,
          "gender" : "M",
          "address" : "990 Mill Road",
          "employer" : "Pheast",
          "email" : "forbeswallace@pheast.com",
          "city" : "Lopezo",
          "state" : "AK"
        }
      },
      {
        "_index" : "bank",
        "_type" : "account",
        "_id" : "136",
        "_score" : 5.4032025,
        "_source" : {
          "account_number" : 136,
          "balance" : 45801,
          "firstname" : "Winnie",
          "lastname" : "Holland",
          "age" : 38,
          "gender" : "M",
          "address" : "198 Mill Lane",
          "employer" : "Neteria",
          "email" : "winnieholland@neteria.com",
          "city" : "Urie",
          "state" : "IL"
        }
      },
      {
        "_index" : "bank",
        "_type" : "account",
        "_id" : "345",
        "_score" : 5.4032025,
        "_source" : {
          "account_number" : 345,
          "balance" : 9812,
          "firstname" : "Parker",
          "lastname" : "Hines",
          "age" : 38,
          "gender" : "M",
          "address" : "715 Mill Avenue",
          "employer" : "Baluba",
          "email" : "parkerhines@baluba.com",
          "city" : "Blackgum",
          "state" : "KY"
        }
      },
      {
        "_index" : "bank",
        "_type" : "account",
        "_id" : "472",
        "_score" : 5.4032025,
        "_source" : {
          "account_number" : 472,
          "balance" : 25571,
          "firstname" : "Lee",
          "lastname" : "Long",
          "age" : 32,
          "gender" : "F",
          "address" : "288 Mill Street",
          "employer" : "Comverges",
          "email" : "leelong@comverges.com",
          "city" : "Movico",
          "state" : "MT"
        }
      }
    ]
  },
  "aggregations" : {
    "ageAgg" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 0,
      "buckets" : [
        {
          "key" : 38,
          "doc_count" : 2
        },
        {
          "key" : 28,
          "doc_count" : 1
        },
        {
          "key" : 32,
          "doc_count" : 1
        }
      ]
    },
    "ageAvg" : {
      "value" : 34.0
    },
    "blanceAvg" : {
      "value" : 25208.0
    }
  }
}

```

### 3.4.聚合内聚合

```json
1.按照年龄分布，并且求各年龄分布内人的平均工资
GET bank/_search
{
  "query": {
    "match_all": {}
  },
  "aggs": {
    "ageAgg": {
      "terms": {
        "field": "age"
      },
      "aggs": {
        "balanceAvg": {
          "avg": {
            "field": "balance"
          }
        }
      }
    }
  },
  "size":0  不返回命中结果
}
```

```json
{
  "took" : 0,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 1000,
      "relation" : "eq"
    },
    "max_score" : null,
    "hits" : [ ]
  },
  "aggregations" : {
    "ageAgg" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 463,
      "buckets" : [
        {
          "key" : 31,
          "doc_count" : 61,
          "balanceAvg" : {
            "value" : 28312.918032786885
          }
        },
        {
          "key" : 39,
          "doc_count" : 60,
          "balanceAvg" : {
            "value" : 25269.583333333332
          }
        },
        {
          "key" : 26,
          "doc_count" : 59,
          "balanceAvg" : {
            "value" : 23194.813559322032
          }
        },
        {
          "key" : 32,
          "doc_count" : 52,
          "balanceAvg" : {
            "value" : 23951.346153846152
          }
        },
        {
          "key" : 35,
          "doc_count" : 52,
          "balanceAvg" : {
            "value" : 22136.69230769231
          }
        },
        {
          "key" : 36,
          "doc_count" : 52,
          "balanceAvg" : {
            "value" : 22174.71153846154
          }
        },
        {
          "key" : 22,
          "doc_count" : 51,
          "balanceAvg" : {
            "value" : 24731.07843137255
          }
        },
        {
          "key" : 28,
          "doc_count" : 51,
          "balanceAvg" : {
            "value" : 28273.882352941175
          }
        },
        {
          "key" : 33,
          "doc_count" : 50,
          "balanceAvg" : {
            "value" : 25093.94
          }
        },
        {
          "key" : 34,
          "doc_count" : 49,
          "balanceAvg" : {
            "value" : 26809.95918367347
          }
        }
      ]
    }
  }
}

```



### 3.5.聚合内聚合内聚合

```json
2.查出年龄分布
  并且这些年龄段中M的平均薪资和F的平均薪资
  以及各年龄段中总体的平均薪资
GET bank/_search
{
  "query": {
    "match_all": {}
  },
  "aggs": {
    "ageAgg": {
      "terms": {
        "field": "age"
      },
      "aggs": {
        "genderAgg": {
          "terms": {
            "field": "gender.keyword"
          },
          "aggs": {
            "balanceAvg": {
              "avg": {
                "field": "balance"
              }
            }
          }
        },
        "ageBalanceAvg": {
          "avg": {
            "field": "balance"
          }
        }
      }
    }
  },
  "size": 0
}
```

```json
{
  "took" : 5,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 1000,
      "relation" : "eq"
    },
    "max_score" : null,
    "hits" : [ ]
  },
  "aggregations" : {
    "ageAgg" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 463,
      "buckets" : [
        {
          "key" : 31,
          "doc_count" : 61,
          "genderAgg" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
              {
                "key" : "M",
                "doc_count" : 35,
                "balanceAvg" : {
                  "value" : 29565.628571428573
                }
              },
              {
                "key" : "F",
                "doc_count" : 26,
                "balanceAvg" : {
                  "value" : 26626.576923076922
                }
              }
            ]
          },
          "ageBalanceAvg" : {
            "value" : 28312.918032786885
          }
        },
        {
          "key" : 39,
          "doc_count" : 60,
          "genderAgg" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
              {
                "key" : "F",
                "doc_count" : 38,
                "balanceAvg" : {
                  "value" : 26348.684210526317
                }
              },
              {
                "key" : "M",
                "doc_count" : 22,
                "balanceAvg" : {
                  "value" : 23405.68181818182
                }
              }
            ]
          },
          "ageBalanceAvg" : {
            "value" : 25269.583333333332
          }
        },
        {
          "key" : 26,
          "doc_count" : 59,
          "genderAgg" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
              {
                "key" : "M",
                "doc_count" : 32,
                "balanceAvg" : {
                  "value" : 25094.78125
                }
              },
              {
                "key" : "F",
                "doc_count" : 27,
                "balanceAvg" : {
                  "value" : 20943.0
                }
              }
            ]
          },
          "ageBalanceAvg" : {
            "value" : 23194.813559322032
          }
        },
        {
          "key" : 32,
          "doc_count" : 52,
          "genderAgg" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
              {
                "key" : "M",
                "doc_count" : 28,
                "balanceAvg" : {
                  "value" : 22941.964285714286
                }
              },
              {
                "key" : "F",
                "doc_count" : 24,
                "balanceAvg" : {
                  "value" : 25128.958333333332
                }
              }
            ]
          },
          "ageBalanceAvg" : {
            "value" : 23951.346153846152
          }
        },
        {
          "key" : 35,
          "doc_count" : 52,
          "genderAgg" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
              {
                "key" : "M",
                "doc_count" : 28,
                "balanceAvg" : {
                  "value" : 24226.321428571428
                }
              },
              {
                "key" : "F",
                "doc_count" : 24,
                "balanceAvg" : {
                  "value" : 19698.791666666668
                }
              }
            ]
          },
          "ageBalanceAvg" : {
            "value" : 22136.69230769231
          }
        },
        {
          "key" : 36,
          "doc_count" : 52,
          "genderAgg" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
              {
                "key" : "M",
                "doc_count" : 31,
                "balanceAvg" : {
                  "value" : 20884.677419354837
                }
              },
              {
                "key" : "F",
                "doc_count" : 21,
                "balanceAvg" : {
                  "value" : 24079.04761904762
                }
              }
            ]
          },
          "ageBalanceAvg" : {
            "value" : 22174.71153846154
          }
        },
        {
          "key" : 22,
          "doc_count" : 51,
          "genderAgg" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
              {
                "key" : "F",
                "doc_count" : 27,
                "balanceAvg" : {
                  "value" : 22152.74074074074
                }
              },
              {
                "key" : "M",
                "doc_count" : 24,
                "balanceAvg" : {
                  "value" : 27631.708333333332
                }
              }
            ]
          },
          "ageBalanceAvg" : {
            "value" : 24731.07843137255
          }
        },
        {
          "key" : 28,
          "doc_count" : 51,
          "genderAgg" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
              {
                "key" : "F",
                "doc_count" : 31,
                "balanceAvg" : {
                  "value" : 27076.8064516129
                }
              },
              {
                "key" : "M",
                "doc_count" : 20,
                "balanceAvg" : {
                  "value" : 30129.35
                }
              }
            ]
          },
          "ageBalanceAvg" : {
            "value" : 28273.882352941175
          }
        },
        {
          "key" : 33,
          "doc_count" : 50,
          "genderAgg" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
              {
                "key" : "F",
                "doc_count" : 26,
                "balanceAvg" : {
                  "value" : 26437.615384615383
                }
              },
              {
                "key" : "M",
                "doc_count" : 24,
                "balanceAvg" : {
                  "value" : 23638.291666666668
                }
              }
            ]
          },
          "ageBalanceAvg" : {
            "value" : 25093.94
          }
        },
        {
          "key" : 34,
          "doc_count" : 49,
          "genderAgg" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets" : [
              {
                "key" : "F",
                "doc_count" : 30,
                "balanceAvg" : {
                  "value" : 26039.166666666668
                }
              },
              {
                "key" : "M",
                "doc_count" : 19,
                "balanceAvg" : {
                  "value" : 28027.0
                }
              }
            ]
          },
          "ageBalanceAvg" : {
            "value" : 26809.95918367347
          }
        }
      ]
    }
  }
}

```

## 4.Mapping

字段类型：

![1634562010741](/1634562010741.png)

```josn
1.映射定义了文档是如何处理的，定义属性字段存储和处理的方式（指定了字段类型、相关性得分）

2.在往es存入数据时，es会根据数据自动分析数据类型

```

### 4.1.查询

```json
1.查询索引下每一个字段的映射
GET /bank/_mapping

其中text属性还可以有子属性keyword，且子属性的type类型=keyword
```



```json
{
  "bank" : {
    "mappings" : {
      "properties" : {
        "account_number" : {
          "type" : "long"
        },
        "address" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "age" : {
          "type" : "long"
        },
        "balance" : {
          "type" : "long"
        },
        "city" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "email" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "employer" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "firstname" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "gender" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "lastname" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "state" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        }
      }
    }
  }
}
```

### 4.2.创建映射

```json
1.创建索引的同时指定字段映射（https://www.elastic.co/guide/en/elasticsearch/reference/7.9/mapping.html）
PUT /my_index
{
  "mappings": {
    "properties": {
      "age":    { "type": "integer", "boost":"2.0" },	// age检索获得相关性得分更大
      "email":  { "type": "keyword"  }, // 精确查找类型
      "name":   { "type": "text"  }     
    }
  }	
}
```

### 4.3.创建新的字段映射

```json
需求：
	在已有的索引中，增加一个字段并且指定其映射（创建索引语句不可重复执行）

实现：
PUT /my_index/_mapping
{
    "properties": {
        "employee_id": {
            "type": "keyword",
            "index": false	// 表示不能用employee_id来检索数据
        }
    }
}
```

### 4.4.更新映射

```json
已存在的映射字段，不能更新。只能创建新的索引进行数据迁移
```

### 4.5.数据迁移

```json
1.创建新索引
PUT /newbank
{
  "mappings": {
    "properties": {
      "account_number": {
        "type": "long"
      },
      "address": {
        "type": "text"
      },
      "age": {
        "type": "integer"
      },
      "balance": {
        "type": "long"
      },
      "city": {
        "type": "keyword"
      },
      "email": {
        "type": "keyword"
      },
      "employer": {
        "type": "keyword"
      },
      "firstname": {
        "type": "text"
      },
      "gender": {
        "type": "keyword"
      },
      "lastname": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      },
      "state": {
        "type": "keyword"
      }
    }
  }
}

2.迁移数据
	1）方法1：7.0之后无类型的数据可以使用此种方法迁移
POST _reindex
{
	"source":{
		"index":"bank"
	},
	"dest":{
		"index":"newbank"
	}
}

	2）方法2：迁移有类型的数据
POST _reindex
{
	"source":{
		"index":"bank",// 源索引
		"type":"account"
	},
	"dest":{
		"index":"newbank"// 目标索引
	}
}

3.查询新索引
GET newbank/_search
GET newbank/_mapping
```



## 5.ES6.0删除类型

```
删除原因：
	1.关系型数据库中数据时独立的，例如两个表中存在相同名称的列也不会影响使用。
	2.ES是基于Lucene开发的搜索引擎，而ES中不同type下名称相同的field最终在Lucene中的处理方式是一样的
	解释：
		1）同一索引下不同类型下但field相同时被认为是同一个，所以需要在type不相等的情况下定义相同的field映射，否则，不同type中的相同字段名称就会在处理中出现冲突的情况【导致Lucene处理效率下降】
		2）去掉type是为了提高ES处理数据的效率

Elasticsearch 7.x：
	URL中的type参数可选
	
Elasticsearch 8.x：
	不再支持URL中的type参数
```

## 6.分词

```json
简介：
	1.分词是将文本拆分成多个词，然后相关性匹配获得相关性得分；
	2.标准分词器【默认分词器】：按照空格来拆分词元

	一个tokenizer(分词器）接收一个字符流，将之分割为独立的tokens(词元，通常是独立的单词），然后输出tokens流。
	例如，whitespace tokenizer【默认分词器】遇到空白字符时分割文本。它会将文本"Quick brown fox!"分割为[Quick, brown, fox!]，该tokenizer(分词器）还负责记录各个term(词条）的顺序或position位置(用于phrase短语和word proximity词近邻查询），以及term(词条）所代表的原始word（单词）的start(起始）和end（结束）的character offsets（字符偏移量）（用于高亮显示搜索的内容）。

	2.Elasticsearch提供了很多内置的分词器，可以用来构建custom analyzers（自定义分词器）。
```

### 6.1.指定分词器分词

```json
1.案例1：
POST _analyze
{
  "analyzer": "standard",
  "text": "ni hao !. ."
}

返回结果：
{
  "tokens" : [
    {
      "token" : "ni",
      "start_offset" : 0,
      "end_offset" : 2,
      "type" : "<ALPHANUM>",
      "position" : 0
    },
    {
      "token" : "hao",
      "start_offset" : 3,
      "end_offset" : 6,
      "type" : "<ALPHANUM>",
      "position" : 1
    }
  ]
}
```

### 6.2.ik分词器

```json
2.案例2：
标准分词器缺点：中文语句会被切割成每个字一个词元，所以需要使用ik分词器
```

#### 6.2.1.安装ik分词器

```json
1.下载ik分词器zip解压包（选择与es版本对应的ik分词器版本v7.4.2）
	1）方式1，直接网页下载后上传至虚拟机
https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.4.2
	2）方式2，直接在虚拟机上下载zip
		2.1.进入elasticsearch容器
		docker exec -it elasticsearch /bin/bash
（也可以不进容器直接进入挂载目录直接进入挂载目录cd /mydata/elasticsearch/plugins）
		2.2.安装wget
			yum install wget
		2.3.使用wegt下载zip
	https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.4.2/elasticsearch-analysis-ik-7.4.2.zip

2.创建ik文件夹
	mkdir ik

3.cd ik，并解压
unzip elasticsearch-analysis-ik-7.4.2.zip

4.删除压缩包
rm -rf *.zip

5.修改权限
chmod -R 777 ik/
	
6.检查ik是否装好，查看bin内是否有可执行文件
docker exec -it elasticsearch /bin/bash
cd bin/
列出所有插件：elasticsearch-plugin list

7.重启elasticsearch
docker restart elasticsearch
```

#### 6.2.2.使用ik分词器

##### ik_smart

```json
智能分词
POST _analyze
{
  "analyzer": "ik_smart",
  "text": "我是中国人"
}

返回结果：
{
  "tokens" : [
    {
      "token" : "我",
      "start_offset" : 0,
      "end_offset" : 1,
      "type" : "CN_CHAR",
      "position" : 0
    },
    {
      "token" : "是",
      "start_offset" : 1,
      "end_offset" : 2,
      "type" : "CN_CHAR",
      "position" : 1
    },
    {
      "token" : "中国人",
      "start_offset" : 2,
      "end_offset" : 5,
      "type" : "CN_WORD",
      "position" : 2
    }
  ]
}
```

##### ik_max_word

```json
ik_max_word：最大的词元组合
POST _analyze
{
  "analyzer": "ik_max_word",
  "text": "我是中国人"
}

返回结果：
{
  "tokens" : [
    {
      "token" : "我",
      "start_offset" : 0,
      "end_offset" : 1,
      "type" : "CN_CHAR",
      "position" : 0
    },
    {
      "token" : "是",
      "start_offset" : 1,
      "end_offset" : 2,
      "type" : "CN_CHAR",
      "position" : 1
    },
    {
      "token" : "中国人",
      "start_offset" : 2,
      "end_offset" : 5,
      "type" : "CN_WORD",
      "position" : 2
    },
    {
      "token" : "中国",
      "start_offset" : 2,
      "end_offset" : 4,
      "type" : "CN_WORD",
      "position" : 3
    },
    {
      "token" : "国人",
      "start_offset" : 3,
      "end_offset" : 5,
      "type" : "CN_WORD",
      "position" : 4
    }
  ]
}
```

#### 6.2.3.自定义词库

```json
简介：
	1.以下demo，无法识别乔碧罗，所以需要自定义词库
POST _analyze
{
  "analyzer": "ik_max_word",
  "text": "乔碧罗殿下"
}
	2.以后有新的词语往fenci.txt添加即可

```

```
两种实现：
	方法1：指定远程词库，ik分词器自己向远程发送请求获得最新词元
		实现：自己编写一个项目处理请求http://192.168.128.130/fenci/myword.txt
	方法2：将词库放在nginx中，使ik分词器向nginx发送请求
```

```json
1.安装nginx（参照环境搭建.md）
2.cd /mydata/nginx/html
3.创建文件夹：mkdir es
	并cd到es内
4.创建.txt词元文档：vi fenci.txt
	输入 乔碧罗，保存退出

5.修改es配置文件，指定词典路径
vi /mydata/elasticsearch/plugins/ik/config/IKAnalyzer.cfg.xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
	<comment>IK Analyzer 扩展配置</comment>
	<!--用户可以在这里配置自己的扩展字典 -->
	<entry key="ext_dict"></entry>
	 <!--用户可以在这里配置自己的扩展停止词字典-->
	<entry key="ext_stopwords"></entry>
	<!--用户可以在这里配置远程扩展字典 -->
	<entry key="remote_ext_dict">http://192.168.56.10/es/fenci.txt</entry>
	<!--用户可以在这里配置远程扩展停止词字典-->
	<!-- <entry key="remote_ext_stopwords">words_location</entry> -->
</properties>


6.重启es：docker restart elasticsearch
7.192.168.56.10:5601
POST _analyze
{
  "analyzer": "ik_max_word",
  "text": "乔碧罗殿下"
}

返回结果：
{
  "tokens" : [
    {
      "token" : "乔碧罗",
      "start_offset" : 0,
      "end_offset" : 3,
      "type" : "CN_WORD",
      "position" : 0
    },
    {
      "token" : "殿下",
      "start_offset" : 3,
      "end_offset" : 5,
      "type" : "CN_WORD",
      "position" : 1
    }
  ]
}
```



#### 6.2.4.给es重新分配内存

```properties
查看环境搭建.md
```

## 7.springboot整合high-level-client

### 简介+文档

**Java High Level REST Client**文档地址：

[Docs](https://www.elastic.co/guide/)

 [Java REST Client [7.8\]](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/index.html) » [Java High Level REST Client](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high.html) » [Getting started](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high-getting-started.html) » Initialization 

```json
1.java操作es有两种方式，
	方式1:
		9300: TCP（建立长连接）
		spring:data-elasticsearch:transport-api.jar;
		springboot版本不同，transport-api.jar不同，不能适配es版本（最多只维护的6.3.8）
		7x已经不建议使用，8以后就要废弃
	
	方式2:
		9200: HTTP
		JestClient：非官方，更新慢
		RestTemplate（springboot自带）：模拟发HTTP 请求，ES很多操作需要自己封装，麻烦
		HttpClient：同上
		Elasticsearch-Rest-Client：官方RestClient，封装了ES操作，API层次分明，最终选择Elasticsearch-Rest-Client（elasticsearch-rest-high-level-client）
		
2.es商品检索工作模式：
	1、给java发送检索条件
	2、java发送请求到es检索商品
	3、java接收返回再返回给前端

问题：为什么不使用js直接向es发送请求？
	1、因为es是后台集群端口，如果对外暴露会有安全隐患，应该由java来统一处理后台集群
	2、如果要使用js，完全可以使用ajax自己封装请求，都不用官方的api了

3.相关代码整合请查看高级篇
```

# 整合检索业务

## 1.创建检索模块

```xml
1、创建gulimall-search（spring initializr）
    group：com.atguigu.gulimall
    artifact：gulimall-search
    description：Elasticsearch检索服务
    package：com.atguigu.gulimall.search
    
    web=>spring web
    nosql=>spring data elasticsearch（不选择，只支持到6.3.8版本）
    
    修改Spring Boot版本：
	<parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.3.2.RELEASE</version>
        <relativePath/>
    </parent>

2、导入依赖，需与es的版本一致：7.4.2
        <dependency>
            <groupId>com.atguigu.gulimall</groupId>
            <artifactId>gulimall-common</artifactId>
            <version>0.0.1-SNAPSHOT</version>
            <exclusions>
                <exclusion>
                    <groupId>com.baomidou</groupId>
                    <artifactId>mybatis-plus-boot-starter</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <!--es的客户端elasticsearch-rest-high-level-client-->
        <dependency>
            <groupId>org.elasticsearch.client</groupId>
            <artifactId>elasticsearch-rest-high-level-client</artifactId>
            <version>7.4.2</version>
        </dependency>

3、在gulimall-search的pom中修改elasticsearch.version版本：
    <properties>
        <java.version>1.8</java.version>
        <elasticsearch.version>7.4.2</elasticsearch.version>
    </properties>
原因：
    springboot指定了es的版本，所以需要覆盖此版本
    查看
spring-boot-starter-parent=》spring-boot-dependencies=》<elasticsearch.version>7.6.2</elasticsearch.version>
    <properties>
        <java.version>1.8</java.version>
        <elasticsearch.version>7.4.2</elasticsearch.version>
    </properties>

4、主模块添加
    <module>gulimall-search</module>

5、nacos配置中心+注册中心配置
@EnableDiscoveryClient

application.yml：
server:
  port: 12000
elasticsearch:
  host: 192.168.56.10
spring:
  application:
    name: gulimall-search
  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848
```

## 2.创建配置类

```java
5、创建es配置类
    【如果是用springdata导入的es，则直接在application.yml配置es的地址就可以了
这里我们需要自己写配置】
找到Initialization【复制代码】：https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high-getting-started-initialization.html

@Configuration
public class GulimallElasticSearch {
    @Bean
    public RestHighLevelClient esRestClient() {
        RestHighLevelClient client = new RestHighLevelClient(
                RestClient.builder(
                        new HttpHost("192.168.56.10", 9200, "http")));// 如果此处是集群，传入多个主机就可以了
        return client;
    }
}

6、在单元测试类中测试
@SpringBootTest
class GulimallSearchApplicationTests {

    @Autowired
    private RestHighLevelClient client;

    @Test
    void contextLoads() {
        System.out.println(client);
    }

}
```

## 3.请求配置项

```java
RequestOptions作用：
    es添加了安全访问规则，需要用RequestOptions对请求封装请求头

1.在GulimallElasticSearchConfig添加通用设置项
public static final RequestOptions COMMON_OPTIONS;

/**
  * 通用设置项
  */
static {
    RequestOptions.Builder builder = RequestOptions.DEFAULT.toBuilder();
    //        builder.addHeader("Authorization", "Bearer " + TOKEN);
    //        builder.setHttpAsyncResponseConsumerFactory(
    //                new HttpAsyncResponseConsumerFactory
    //                        .HeapBufferedResponseConsumerFactory(30 * 1024 * 1024 * 1024));
    COMMON_OPTIONS = builder.build();
}
```

## 4.测试

### 4.1.编写测试类

```java
1.版本2.1.8：
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>

@RunWith(SpringRunner.class)// 使用spring驱动
@SpringBootTest
public class GulimallSearchApplicationTests {

    @Autowired
    private RestHighLevelClient client;

    @Test
    void testEs() {
        System.out.println(client);
    }
}

2.版本2.3.2：
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
            <exclusions>
                <exclusion>
                    <groupId>org.junit.vintage</groupId>
                    <artifactId>junit-vintage-engine</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
    
@SpringBootTest
class GulimallSearchApplicationTests {

    @Autowired
    private RestHighLevelClient client;

    @Test
    void testEs() {
        System.out.println(client);
    }
}
```

### 4.2.同步保存/更新数据

```properties
1.构建存储数据的4种方式，查看下图（方式1、方式2用的多）：【构建IndexRequest】
	jsonString
	Map<String, Object>

2.保存IndexRequest
	2.1.同步保存：
		client.index(request, RequestOptions.DEFAULT);
		
	2.2.异步保存
		client.indexAsync(request, RequestOptions.DEFAULT, listener);
```

```java
@Autowired
private RestHighLevelClient client;

@Test
void indexData() throws IOException {
    // 1、构建创建或更新请求，指定索引users
    IndexRequest indexRequest = new IndexRequest("users");
    // 2、设置id
    indexRequest.id("1");// 数据的id
    // 方式一：直接设置数据项
    //users.source("userName", "zhangsan", "gender", "M", "age", "18");
    User user = new User("lisi", "M", 22);
    // 3、绑定数据与请求
    // 方式二：设置json串格式数据
    indexRequest.source(JSON.toJSONString(user), XContentType.JSON);
    // 4、执行：同步
    IndexResponse index = client.index(indexRequest, GulimallElasticSearchConfig.COMMON_OPTIONS);
    // 5、提取响应数据
    System.out.println(index);
}
```

方式1：jsonString

![1634914895427](/1634914895427.png)

方式2：Map<String, Object>

![1634914984175](/1634914984175.png)

方式3：XContentBuilder（内容构造器）

![1634915043054](/1634915043054.png)

方式4：

![1634915088215](/1634915088215.png)

### 4.3.检索数据

```properties
1、参照文档：
https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high-search.html
```

```properties
1.需求：1、检索address中包含mill
	   2、年龄分布
	   3、平均薪资

2.json查询参数
GET newbank/_search
{
  "query": {
    "match": {
      "address": "mill"
    }
  },
  "aggs": {
    "ageAgg": {
      "terms": {
        "field": "age",
        "size": 100
      }
    },
    "balanceAvg": {
      "avg": {
        "field": "balance"
      }
    }
  }
}
```

查询结果：

 ![1634920614495](/1634920614495.png)

```java
/**
 * 从es中查询数据
 * 1、创建检索请求
 *      SearchRequest searchRequest = new SearchRequest("newbank")
 * 2、创建检索条件构建对象（SearchSourceBuilder用于构建检索条件的builder对象）
 *      SearchSourceBuilder sourceBuilder = new SearchSourceBuilder()
 *      绑定操作：
 *         sourceBuilder.sort("age");
 *         sourceBuilder.from(1);
 *         sourceBuilder.size(10);
 *         sourceBuilder.aggregation(AggregationBuilders.terms("ageAgg").field("age").size(10));
 *         sourceBuilder.aggregation(AggregationBuilders.avg("balanceAvg").field("balance"));
 *         sourceBuilder.query(QueryBuilders.matchAllQuery("address", "mill"));
 *         sourceBuilder.query(QueryBuilders.boolQuery());
 * 3、请求绑定条件
 *      searchRequest.source(sourceBuilder);
 * 4、执行请求，接收结果
 * SearchResponse searchResponse = client.search(searchRequest, GulimallElasticSearchConfig.COMMON_OPTIONS);
 * 5、获取命中结果
 *      SearchHit[] hits = searchResponse.getHits().getHits();
 *      Account account = JSON.parseObject(hit.getSourceAsString(), Account.class);
 * 6、获取分组结果
 *      Aggregations aggregations = searchResponse.getAggregations();
 *      年龄分布
 *      Terms ageAgg = aggregations.get("ageAgg");
 *      for (Terms.Bucket bucket : ageAgg.getBuckets()) {
 *          System.out.println("年龄：" + bucket.getKeyAsString() + "--人数： " + bucket.getDocCount());
 *      }
 *      平均工资
 *      Avg balanceAvg = aggregations.get("balanceAvg");
 *      double balance = balanceAvg.getValue();
 */
@Test
void searchData() throws IOException {
    // 1、创建检索请求，自定索引（调用该方法可以切换索引searchRequest.indices("bank")）
    SearchRequest searchRequest = new SearchRequest("newbank");
    // 2、构建检索条件，DSL
    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    /**
         * GET bank/_search
         * {
         *   "query": {
         *     "bool": {
         *       "must": [
         *         {
         *           "match": {
         *             "address": "mill"
         *           }
         *         }
         *       ]
         *     }
         *   },
         *   "aggs": {
         *     "ageAgg": {
         *       "terms": {
         *         "field": "age",
         *         "size": 10
         *       }
         *     },
         *     "blanceAvg":{
         *       "avg": {
         *         "field": "balance"
         *       }
         *     }
         *   }
         * }
         * 需求：
         *  搜索条件：1、检索address中包含mill的所有人
         *  分组条件：1、年龄分布
         *           2、平均薪资
         */
    // 模糊匹配address=mill
    sourceBuilder.query(QueryBuilders.matchQuery("address", "mill"));
    // 年龄分布，取前10条
    TermsAggregationBuilder termsAggregationBuilder = AggregationBuilders.terms("ageAgg").field("age").size(10);
    sourceBuilder.aggregation(termsAggregationBuilder);
    // 平均薪资
    AvgAggregationBuilder avgAggregationBuilder = AggregationBuilders.avg("balanceAvg").field("balance");
    sourceBuilder.aggregation(avgAggregationBuilder);
    System.out.println("检索条件:" + sourceBuilder);
    // 3、检索请求绑定条件
    searchRequest.source(sourceBuilder);
    // 4、执行请求，接收结果
    SearchResponse searchResponse = client.search(searchRequest, GulimallElasticSearchConfig.COMMON_OPTIONS);
    // 5、获取命中的数据【Map map = JSON.parseObject(searchResponse.toString(), Map.class)】
    SearchHit[] hits = searchResponse.getHits().getHits();
    for (SearchHit hit : hits) {
        // "hits" : [
        //      {
        //        "_index" : "newbank",
        //        "_type" : "_doc",
        //        "_id" : "10",
        //        "_score" : null,
        //        "_source" : {
        //          "account_number" : 10,
        //          "balance" : 46170,
        //          "firstname" : "Dominique",
        //          "lastname" : "Park",
        //          "age" : 37,
        //          "gender" : "F",
        //          "address" : "100 Gatling Place",
        //          "employer" : "Conjurica",
        //          "email" : "dominiquepark@conjurica.com",
        //          "city" : "Omar",
        //          "state" : "NJ"
        //        },
        //        "sort" : [
        //          10
        //        ]
        //      }
        //            hit.getIndex();hit.getType();hit.getId();
        // 将_source封装Object对象
        Account account = JSON.parseObject(hit.getSourceAsString(), Account.class);
        System.out.println("搜索结果： " + account);
    }
    // 获得分组结果
    Aggregations aggregations = searchResponse.getAggregations();
    // 通过名字获得年龄分布
    Terms ageAgg = aggregations.get("ageAgg");
    for (Terms.Bucket bucket : ageAgg.getBuckets()) {
        System.out.println("年龄：" + bucket.getKeyAsString() + "--人数： " + bucket.getDocCount());
    }
    // 获取平均薪资
    Avg balanceAvg = aggregations.get("balanceAvg");
    System.out.println("薪资平均值： " + balanceAvg.getValue());
}

@Data
static class Account {
    private int account_number;
    private int balance;
    private String firstname;
    private String lastname;
    private int age;
    private String gender;
    private String address;
    private String employer;
    private String email;
    private String city;
    private String state;

    @Override
    public String toString() {
        return "Account{" +
            "account_number=" + account_number +
            ", balance=" + balance +
            ", firstname='" + firstname + '\'' +
            ", lastname='" + lastname + '\'' +
            ", age=" + age +
            ", gender='" + gender + '\'' +
            ", address='" + address + '\'' +
            ", employer='" + employer + '\'' +
            ", email='" + email + '\'' +
            ", city='" + city + '\'' +
            ", state='" + state + '\'' +
            '}';
    }
}
```







